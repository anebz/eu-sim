{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import DocumentPoolEmbeddings, FlairEmbeddings, BertEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_filename = \"goldstandard_baskisch.csv\"\n",
    "\n",
    "def get_gold_sentences(filename):\n",
    "    gold_sentences = {}\n",
    "    with open(filename, 'rt') as f_p:\n",
    "        for line in f_p:\n",
    "            if line.startswith('\"origin\"'): # header\n",
    "                continue\n",
    "            \n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            line = line.rstrip()\n",
    "\n",
    "            line = line.replace('\"', '')\n",
    "            \n",
    "            splitted = line.split('\\t')\n",
    "            \n",
    "            gold = splitted[0]\n",
    "            \n",
    "            sim_sentences = splitted[1:11]\n",
    "            \n",
    "            if gold:\n",
    "                gold_sentences[gold] = sim_sentences\n",
    "            \n",
    "    return gold_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarities(gold, sim_sentences, embeddings):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for sentence in sim_sentences:\n",
    "        query = gold\n",
    "\n",
    "        q = Sentence(query)\n",
    "        embeddings.embed(q)\n",
    "        \n",
    "        s = Sentence(sentence)\n",
    "        embeddings.embed(s)\n",
    "\n",
    "        assert q.embedding.shape == s.embedding.shape\n",
    "        \n",
    "        cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "        prox = cos(q.embedding, s.embedding)\n",
    "    \n",
    "        similarities.append(round(prox.item(), 4))\n",
    "        \n",
    "    return similarities\n",
    "\n",
    "def print_similarities(gold, sim_sentences, similarities):\n",
    "        \n",
    "    print(f\"Example: {gold}\")\n",
    "    \n",
    "    for sentence, similarity in zip(sim_sentences, similarities) :\n",
    "        print(f\"{sentence} - {similarity}\")\n",
    "    \n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change code here ;)\n",
    "\n",
    "gold_sentences = get_gold_sentences(gold_filename)\n",
    "\n",
    "flair_embeddings = DocumentPoolEmbeddings([FlairEmbeddings('eu-forward'), \n",
    "                                     FlairEmbeddings('eu-backward')\n",
    "                                    ])\n",
    "\n",
    "# See BERT paper, section 5.3 and table 7\n",
    "bert_layers = '-1,-2,-3,-4'\n",
    "\n",
    "bert_cased_embeddings = DocumentPoolEmbeddings([BertEmbeddings('bert-base-multilingual-cased',\n",
    "                                                               layers=bert_layers)])\n",
    "\n",
    "bert_uncased_embeddings = DocumentPoolEmbeddings([BertEmbeddings('bert-base-multilingual-uncased',\n",
    "                                                                 layers=bert_layers)])\n",
    "\n",
    "#ELMo and ELMo Transformer are coming soon ;)\n",
    "\n",
    "for gold, sim_sentences in gold_sentences.items():\n",
    "    similarities = calculate_similarities(gold, sim_sentences, bert_uncased_embeddings)\n",
    "    \n",
    "    print_similarities(gold, sim_sentences, similarities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
